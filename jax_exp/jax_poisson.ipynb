{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64e8da43",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1 * int(1e4)\n",
    "pbs = 32\n",
    "q = 0.5\n",
    "\n",
    "alpha = 1e-9 # failure prob.\n",
    "\n",
    "from scipy.stats import binom\n",
    "\n",
    "k = 1\n",
    "binom_dist = binom(n, q)\n",
    "while True:\n",
    "    right_prob = binom_dist.sf(k * pbs)\n",
    "    if right_prob < alpha:\n",
    "        break\n",
    "    k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "801f3ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0263387747110406e-10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_dist.sf(k * pbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a108b3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0033293710926755e-08"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binom_dist.sf((k-1) * pbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa2f92a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5312"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k * pbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df5637d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "465c2722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax.lax import fori_loop\n",
    "mlbs = k * pbs\n",
    "Xs = jax.random.normal(jax.random.PRNGKey(123), (n,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e18695ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([ 0.7200799 ,  0.29004744,  0.3784297 , ...,  0.06939417,\n",
       "       -0.8384669 , -0.55408597], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a64b1cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5312"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6958a822",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice_rng, binom_rng = jax.random.split(jax.random.PRNGKey(0), 2)\n",
    "logical_batch = jax.random.choice(choice_rng, Xs, shape=(mlbs,), replace=False)\n",
    "physical_batches = jnp.array(jnp.split(logical_batch, k))\n",
    "\n",
    "actual_logical_bs = jax.random.bernoulli(binom_rng, q, shape=(n,)).sum()\n",
    "masks = jnp.array(jnp.split((jnp.arange(mlbs) < actual_logical_bs), k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "069d2553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jaxlib.xla_extension.ArrayImpl"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(logical_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2ebda62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(24962, dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_logical_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b78a7b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "803"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4dd2de1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(masks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c29460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(734, dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(32*803)-actual_logical_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3c3c75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "780 32\n",
      "781 32\n",
      "782 32\n",
      "783 32\n",
      "784 32\n",
      "785 32\n",
      "786 32\n",
      "787 32\n",
      "788 32\n",
      "789 32\n",
      "790 32\n",
      "791 32\n",
      "792 32\n",
      "793 32\n",
      "794 32\n",
      "795 32\n",
      "796 32\n",
      "797 32\n",
      "798 32\n",
      "799 32\n",
      "800 32\n",
      "801 32\n",
      "802 32\n"
     ]
    }
   ],
   "source": [
    "for i,mb in enumerate(masks):\n",
    "    if mb.all() == False:\n",
    "        print(i,len(mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b6ecad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_iter(t_iter, args):\n",
    "    choice_rng, binom_rng = jax.random.split(jax.random.PRNGKey(t_iter), 2)\n",
    "    logical_batch = jax.random.choice(choice_rng, Xs, shape=(mlbs,), replace=False)\n",
    "    physical_batches = jnp.array(jnp.split(logical_batch, k))\n",
    "    \n",
    "    actual_logical_bs = jax.random.bernoulli(binom_rng, q, shape=(n,)).sum()\n",
    "    masks = jnp.array(jnp.split((jnp.arange(mlbs) < actual_logical_bs), k))\n",
    "\n",
    "    def foo(t, args):\n",
    "        cumulative_sum_so_far = args\n",
    "        mask = masks[t]\n",
    "        pb_sum = (physical_batches[t] * mask).sum()\n",
    "        return cumulative_sum_so_far + pb_sum\n",
    "\n",
    "    final_sum = fori_loop(0, k, foo, 0.)\n",
    "    \n",
    "    # add noise to grads\n",
    "    # update parameters\n",
    "    # instead of final sum, you would pass the updated params, or whatever to the next iteration\n",
    "    return final_sum\n",
    "final_result = fori_loop(0, 10, single_iter, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47d80a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array(85.314644, dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70a87894",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flax.linen as nn\n",
    "import optax\n",
    "from flax.core.frozen_dict import freeze,unfreeze,FrozenDict\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c6ecab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_key, params_key= jax.random.split(key=jax.random.PRNGKey(1),num=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2007778",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \"\"\"A simple CNN model.\"\"\"\n",
    "\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Conv(features=64, kernel_size=(7, 7),strides=2)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        #x = nn.Conv(features=64, kernel_size=(3, 3))(x)\n",
    "        #x = nn.relu(x)\n",
    "        #x = nn.avg_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        x = x.reshape((x.shape[0], -1))  # flatten\n",
    "        x = nn.Dense(features=256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(features=100)(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "input_shape = (1,3,32,32)\n",
    "#But then, we need to split it in order to get random numbers\n",
    "\n",
    "\n",
    "#The init function needs an example of the correct dimensions, to infer the dimensions.\n",
    "#They are not explicitly writen in the module, instead, the model infer them with the first example.\n",
    "x = jax.random.normal(params_key, input_shape)\n",
    "\n",
    "main_rng, init_rng, dropout_init_rng = jax.random.split(main_key, 3)\n",
    "#Initialize the model\n",
    "variables = model.init({'params':init_rng},x)\n",
    "#variables = model.init({'params':main_key}, batch)\n",
    "model.apply(variables, x)\n",
    "model = model\n",
    "params = variables['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bf6adc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = unfreeze(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "acf10e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "\n",
    "DATA_MEANS2 = (0.485, 0.456, 0.406)\n",
    "DATA_STD2 =  (0.229, 0.224, 0.225)\n",
    "\n",
    "def image_to_numpy_wo_t(img):\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "    img = ((img / 255.) - DATA_MEANS2) / DATA_STD2\n",
    "    img = np.transpose(img,[2,0,1])\n",
    "    return img\n",
    "\n",
    "transformation = torchvision.transforms.Compose([\n",
    "        #torchvision.transforms.Resize(224),\n",
    "        image_to_numpy_wo_t,\n",
    "        #torchvision.transforms.ToTensor(),\n",
    "        #torchvision.transforms.Normalize(DATA_MEANS,DATA_STD),\n",
    "    ])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10(root='../data_cifar10/',train=True,download=True,transform=transformation)\n",
    "train_loader = data.DataLoader(train_set,batch_size=k*pbs,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "706e4178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5312"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "24aaf1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'> 5312 (5312, 3, 32, 32)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'> 5312 (5312,)\n",
      "[[[[-0. -0. -0. ...  0. -0.  0.]\n",
      "   [-0. -0. -0. ...  0.  0.  0.]\n",
      "   [-0. -0. -0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [-0. -0. -0. ...  0.  0.  0.]\n",
      "   [-0. -0. -0. ...  0.  0.  0.]\n",
      "   [-0. -0. -0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ...  0.  0.  0.]\n",
      "   [-0. -0. -0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0. -0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ... -0. -0. -0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]]\n",
      "\n",
      "\n",
      " [[[-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]]\n",
      "\n",
      "  [[-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]]]\n",
      "\n",
      "\n",
      " [[[-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]]\n",
      "\n",
      "  [[ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0. -0. -0. ... -0. -0.  0.]\n",
      "   [ 0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]\n",
      "   [ 0.  0.  0. ...  0.  0.  0.]]\n",
      "\n",
      "  [[-0. -0. -0. ...  0.  0.  0.]\n",
      "   [ 0. -0. -0. ... -0.  0.  0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   ...\n",
      "   [-0. -0. -0. ... -0.  0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]\n",
      "   [-0. -0. -0. ... -0. -0. -0.]]]]\n",
      "final sum 0\n"
     ]
    }
   ],
   "source": [
    "acc_sum = 0\n",
    "for batch_idx,(x,y) in enumerate(train_loader): #logical\n",
    "\n",
    "    print(batch_idx)\n",
    "    #print(type(x),x[0].shape)\n",
    "    x  = jnp.array(x)\n",
    "    y = jnp.array(y)\n",
    "    print(type(x),len(x),x.shape)\n",
    "    print(type(y),len(y),y.shape)\n",
    "\n",
    "    diff = len(y) % k\n",
    "\n",
    "    if diff > 0:\n",
    "\n",
    "        x = jnp.pad(x, ((0, k - diff), (0, 0), (0, 0), (0, 0)), mode='constant')\n",
    "        y = jnp.pad(y, ((0, k - diff)), mode='constant')\n",
    "        print('new shape',x.shape,y.shape)\n",
    "    \n",
    "    batch_size = len(x)\n",
    "\n",
    "    choice_rng, binom_rng = jax.random.split(jax.random.PRNGKey(batch_idx), 2)\n",
    "\n",
    "    physical_batches = jnp.array(jnp.split(x, k))\n",
    "    physical_labels = jnp.array(jnp.split(y,k))\n",
    "    actual_logical_bs = jax.random.bernoulli(binom_rng, q, shape=(n,)).sum()\n",
    "    masks = jnp.array(jnp.split((jnp.arange(batch_size) < actual_logical_bs), k))\n",
    "\n",
    "    b = physical_batches[802]*masks[802]\n",
    "    print(b)\n",
    "    break\n",
    "\n",
    "    print(len(masks))\n",
    "    print(actual_logical_bs)\n",
    "    def foo(t, args):\n",
    "        cumulative_sum_so_far = args\n",
    "        mask = masks[t]\n",
    "        pb_sum = (physical_labels[t] * mask).sum()\n",
    "        return cumulative_sum_so_far + pb_sum\n",
    "\n",
    "    final_sum = fori_loop(0, k, foo, 0.)\n",
    "    print('final sum',batch_idx,final_sum)\n",
    "    acc_sum += final_sum\n",
    "print('final sum',acc_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6699a445",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = jnp.ones((5,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44dac199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([1., 1., 1., 1., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.pad(a, ((0, 2),), mode='constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ae1e1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(params,batch):\n",
    "    inputs,targets = batch\n",
    "    logits = model.apply({'params':params},inputs)\n",
    "    predicted_class = jnp.argmax(logits,axis=-1)\n",
    "\n",
    "    cross_loss = optax.softmax_cross_entropy_with_integer_labels(logits, targets).mean()\n",
    "\n",
    "    vals = predicted_class == targets\n",
    "    acc = jnp.mean(vals)\n",
    "    cor = jnp.sum(vals)\n",
    "\n",
    "    return cross_loss,(acc,cor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "577c84c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_private_update(params,batch):\n",
    "    (loss_val,(acc,cor)), grads = jax.value_and_grad(loss,has_aux=True)(params,batch)\n",
    "    return grads,loss_val,acc,cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e1238037",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.00031"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bde2eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optax.adam(learning_rate=lr)\n",
    "opt_state = optimizer.init(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05d2274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_acc_update(grads,opt_state,params):\n",
    "    updates,opt_state = optimizer.update(grads,opt_state,params)\n",
    "    params = optax.apply_updates(params,updates)\n",
    "    return params,opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3af8a269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'> 5312 (5312, 3, 32, 32)\n",
      "<class 'jaxlib.xla_extension.ArrayImpl'> 5312 (5312,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected dict, got FrozenDict({\n    Conv_0: {\n        bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n        kernel: Array([[[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               ...,\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n    },\n    Dense_0: {\n        bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0.], dtype=float32),\n        kernel: Array([[0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               ...,\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n    },\n    Dense_1: {\n        bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float32),\n        kernel: Array([[0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               ...,\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n    },\n}).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[75], line 40\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m jax\u001b[38;5;241m.\u001b[39mtree_util\u001b[38;5;241m.\u001b[39mtree_map(\n\u001b[1;32m     36\u001b[0m                         functools\u001b[38;5;241m.\u001b[39mpartial(_acc_update),\n\u001b[1;32m     37\u001b[0m                         grads, acc_grad)\n\u001b[1;32m     39\u001b[0m accumulated_gradients \u001b[38;5;241m=\u001b[39m fori_loop(\u001b[38;5;241m0\u001b[39m, k, foo, acc_grads)\n\u001b[0;32m---> 40\u001b[0m params,opt_state \u001b[38;5;241m=\u001b[39m \u001b[43mgrad_acc_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccumulated_gradients\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[67], line 2\u001b[0m, in \u001b[0;36mgrad_acc_update\u001b[0;34m(grads, opt_state, params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad_acc_update\u001b[39m(grads,opt_state,params):\n\u001b[0;32m----> 2\u001b[0m     updates,opt_state \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     params \u001b[38;5;241m=\u001b[39m optax\u001b[38;5;241m.\u001b[39mapply_updates(params,updates)\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m params,opt_state\n",
      "File \u001b[0;32m~/Documents/privacy_env/lib/python3.10/site-packages/optax/_src/combine.py:59\u001b[0m, in \u001b[0;36mchain.<locals>.update_fn\u001b[0;34m(updates, state, params, **extra_args)\u001b[0m\n\u001b[1;32m     57\u001b[0m new_state \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m s, fn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(state, update_fns):\n\u001b[0;32m---> 59\u001b[0m   updates, new_s \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m   new_state\u001b[38;5;241m.\u001b[39mappend(new_s)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m updates, \u001b[38;5;28mtuple\u001b[39m(new_state)\n",
      "File \u001b[0;32m~/Documents/privacy_env/lib/python3.10/site-packages/optax/_src/base.py:311\u001b[0m, in \u001b[0;36mwith_extra_args_support.<locals>.update\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(updates, state, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_args):\n\u001b[1;32m    310\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m extra_args\n\u001b[0;32m--> 311\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/privacy_env/lib/python3.10/site-packages/optax/_src/transform.py:342\u001b[0m, in \u001b[0;36mscale_by_adam.<locals>.update_fn\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fn\u001b[39m(updates, state, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    341\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m params\n\u001b[0;32m--> 342\u001b[0m   mu \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_moment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m   nu \u001b[38;5;241m=\u001b[39m update_moment_per_elem_norm(updates, state\u001b[38;5;241m.\u001b[39mnu, b2, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    344\u001b[0m   count_inc \u001b[38;5;241m=\u001b[39m numerics\u001b[38;5;241m.\u001b[39msafe_int32_increment(state\u001b[38;5;241m.\u001b[39mcount)\n",
      "File \u001b[0;32m~/Documents/privacy_env/lib/python3.10/site-packages/optax/_src/transform.py:83\u001b[0m, in \u001b[0;36mupdate_moment\u001b[0;34m(updates, moments, decay, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_moment\u001b[39m(updates, moments, decay, order):\n\u001b[1;32m     82\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the exponential moving average of the `order`-th moment.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 83\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmoments\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/privacy_env/lib/python3.10/site-packages/jax/_src/tree_util.py:243\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m  [[5, 7, 9], [6, 1, 2]]\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 243\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m~/Documents/privacy_env/lib/python3.10/site-packages/jax/_src/tree_util.py:243\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \n\u001b[1;32m    212\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m  [[5, 7, 9], [6, 1, 2]]\u001b[39;00m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    242\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 243\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [\u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "\u001b[0;31mValueError\u001b[0m: Expected dict, got FrozenDict({\n    Conv_0: {\n        bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n        kernel: Array([[[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               ...,\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]],\n        \n        \n               [[[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                ...,\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]],\n        \n                [[0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 ...,\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.],\n                 [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32),\n    },\n    Dense_0: {\n        bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0.], dtype=float32),\n        kernel: Array([[0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               ...,\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n    },\n    Dense_1: {\n        bias: Array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n               0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],      dtype=float32),\n        kernel: Array([[0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               ...,\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.],\n               [0., 0., 0., ..., 0., 0., 0.]], dtype=float32),\n    },\n})."
     ]
    }
   ],
   "source": [
    "acc_sum = 0\n",
    "_acc_update = lambda grad, acc : grad + acc\n",
    "for batch_idx,(x,y) in enumerate(train_loader): #logical\n",
    "\n",
    "    print(batch_idx)\n",
    "    #print(type(x),x[0].shape)\n",
    "    x  = jnp.array(x)\n",
    "    y = jnp.array(y)\n",
    "    print(type(x),len(x),x.shape)\n",
    "    print(type(y),len(y),y.shape)\n",
    "\n",
    "    diff = len(y) % k\n",
    "\n",
    "    if diff > 0:\n",
    "\n",
    "        x = jnp.pad(x, ((0, k - diff), (0, 0), (0, 0), (0, 0)), mode='constant')\n",
    "        y = jnp.pad(y, ((0, k - diff)), mode='constant')\n",
    "        print('new shape',x.shape,y.shape)\n",
    "    \n",
    "    batch_size = len(x)\n",
    "\n",
    "    choice_rng, binom_rng = jax.random.split(jax.random.PRNGKey(batch_idx), 2)\n",
    "\n",
    "    physical_batches = jnp.array(jnp.split(x, k))\n",
    "    physical_labels = jnp.array(jnp.split(y,k))\n",
    "    actual_logical_bs = jax.random.bernoulli(binom_rng, q, shape=(n,)).sum()\n",
    "    masks = jnp.array(jnp.split((jnp.arange(batch_size) < actual_logical_bs), k))\n",
    "    acc_grads = jax.tree_util.tree_map(jnp.zeros_like,params)\n",
    "    def foo(t, args):\n",
    "        acc_grad = args\n",
    "        mask = masks[t]\n",
    "        data_x = (physical_batches[t] * mask)\n",
    "        data_y = (physical_labels[t] * mask)\n",
    "        grads,loss,acc,cor = non_private_update(params,(data_x,data_y))\n",
    "        return jax.tree_util.tree_map(\n",
    "                            functools.partial(_acc_update),\n",
    "                            grads, acc_grad)\n",
    "\n",
    "    accumulated_gradients = fori_loop(0, k, foo, acc_grads)\n",
    "    print('update?',accumulated_gradients)\n",
    "    params,opt_state = grad_acc_update(accumulated_gradients,opt_state,params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317c7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
