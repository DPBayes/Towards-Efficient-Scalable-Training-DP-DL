{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Notebook\n",
    "\n",
    "In this notebook we show how to use the library to implement computionally-efficient DP-SGD with JAX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup (skip until 1. if you don't need the details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "import jax\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Enviroment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \".90\"\n",
    "os.environ[\"XLA_PYTHON_CLIENT_ALLOCATOR\"] = \"platform\"\n",
    "\n",
    "jax.clear_caches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Use GPU or CPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Arguments\n",
    "\n",
    "Here you can change the value of the arguments by changing the default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used args: Namespace(lr=0.001, num_steps=10, logical_bs=100, clipping_norm=1, target_epsilon=8, target_delta=1e-05, physical_bs=2, accountant='pld', seed=1234)\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--lr\", default=0.001, type=float, help=\"learning rate\")\n",
    "parser.add_argument(\"--num_steps\", default=10, type=int, help=\"Number of steps\")\n",
    "parser.add_argument(\"--logical_bs\", default=100, type=int, help=\"Logical batch size\")\n",
    "parser.add_argument(\"--clipping_norm\", default=1, type=float, help=\"max grad norm\")\n",
    "\n",
    "parser.add_argument(\"--target_epsilon\", default=8, type=float, help=\"target epsilon\")\n",
    "parser.add_argument(\"--target_delta\", default=1e-5, type=float, help=\"target delta\")\n",
    "\n",
    "parser.add_argument(\"--physical_bs\", default=2, type=int, help=\"Physical Batch Size\")\n",
    "parser.add_argument(\"--accountant\", default=\"pld\", type=str, help=\"The privacy accountant for DP training.\")\n",
    "\n",
    "parser.add_argument(\"--seed\", default=1234, type=int)\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "print(\"Used args:\", args, flush=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setting up dataset, model and DP accounting\n",
    "We show you how to setup the dataset, model and how the DP accounting works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Dataset\n",
    "\n",
    "We load the dataset from [Hugging Face](https://huggingface.co/) but the only important thing is to have the data available as arrays. Hugging Face supports this nicely but there might be other or even better ways to achieve this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f68b3ec011b4956a18023540ae0e1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/120M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b562138859c84f46810661aac1c65847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/23.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb1711a018147319af91248ce21a72b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246aef676281471da55cd5df076146cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from dpsgdjax.data import load_from_huggingface\n",
    "\n",
    "train_images, train_labels, test_images, test_labels = load_from_huggingface(\n",
    "    \"uoft-cs/cifar10\", cache_dir=None, feature_name=\"img\"\n",
    ")\n",
    "ORIG_IMAGE_DIMENSION, RESIZED_IMAGE_DIMENSION = 32, 32\n",
    "train_images = train_images[train_labels < 2].transpose(0, 3, 1, 2)\n",
    "train_labels = train_labels[train_labels < 2]\n",
    "test_images = test_images[test_labels < 2].transpose(0, 3, 1, 2)\n",
    "test_labels = test_labels[test_labels < 2]\n",
    "\n",
    "\n",
    "num_classes = 2\n",
    "dataset_size = len(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Model\n",
    "\n",
    "We create a `flax.training.train_state.TrainState` and load pre-trained weights from [Hugging Face](https://huggingface.co/) using the `create_train_state` function that we provide in `src.models.py`. In this particular example, we load the weights of a simple Conv_Net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model name small\n"
     ]
    }
   ],
   "source": [
    "from dpsgdjax.models import create_train_state\n",
    "from collections import namedtuple\n",
    "\n",
    "optimizer_config = namedtuple(\"Config\", [\"learning_rate\"])\n",
    "optimizer_config.learning_rate = args.lr\n",
    "\n",
    "state = create_train_state(\n",
    "    model_name=\"small\",\n",
    "    num_classes=num_classes,\n",
    "    image_dimension=RESIZED_IMAGE_DIMENSION,\n",
    "    optimizer_config=optimizer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 DP accounting\n",
    "\n",
    "First, we compute the `subsampling_ratio` based on the `dataset_size` and the (expected) `logical_bs`. Then we compute the required DP-SGD `noise_std` based on the `subsampling_ratio` and the `num_steps` for a particular pair of `target_epsilon` and `target_delta` using a privacy accountant. At the moment the Privacy Loss Distributions (PLDs) and RDP accounting from the google [dp_accounting](https://github.com/google/differential-privacy/tree/main/python/dp_accounting) library are supported. \n",
    "\n",
    "*Note: You can also use the accounting tooling of other libraries such as the PyTorch based [opacus](https://github.com/pytorch/opacus).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpsgdjax.dp_accounting_utils import calculate_noise\n",
    "if dataset_size * args.target_delta > 1.0:\n",
    "    warnings.warn(\"Your delta might be too high.\")\n",
    "\n",
    "subsampling_ratio = 1 / math.ceil(dataset_size / args.logical_bs)\n",
    "\n",
    "noise_std = calculate_noise(\n",
    "        sample_rate=subsampling_ratio,\n",
    "        target_epsilon=args.target_epsilon,\n",
    "        target_delta=args.target_delta,\n",
    "        steps=args.num_steps,\n",
    "        accountant=args.accountant,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Function to process one physical batch\n",
    "\n",
    "First we define the function that computes per example gradients (`compute_per_example_gradients_physical_batch`) and clips them (`clip_and_accumulate_physical_batch`). This function can be jit compiled and then used in the full training loop later (see 3.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpsgdjax.jax_mask_efficient import (\n",
    "    compute_per_example_gradients_physical_batch,\n",
    "    add_trees,\n",
    "    clip_physical_batch,\n",
    "    accumulate_physical_batch,\n",
    ")\n",
    "\n",
    "@jax.jit\n",
    "def process_physical_batch(t, params):\n",
    "    (\n",
    "        state,\n",
    "        accumulated_clipped_grads,\n",
    "        logical_batch_X,\n",
    "        logical_batch_y,\n",
    "        masks,\n",
    "    ) = params\n",
    "    # slice\n",
    "    start_idx = t * args.physical_bs\n",
    "    pb = jax.lax.dynamic_slice(\n",
    "        logical_batch_X,\n",
    "        (start_idx, 0, 0, 0, 0),\n",
    "        (args.physical_bs, 1, 3, ORIG_IMAGE_DIMENSION, ORIG_IMAGE_DIMENSION),\n",
    "    )\n",
    "    yb = jax.lax.dynamic_slice(logical_batch_y, (start_idx,), (args.physical_bs,))\n",
    "    mask = jax.lax.dynamic_slice(masks, (start_idx,), (args.physical_bs,))\n",
    "\n",
    "    # compute grads and clip\n",
    "    per_example_gradients = compute_per_example_gradients_physical_batch(state, pb, yb, num_classes)\n",
    "    clipped_grads_from_pb = clip_physical_batch(per_example_gradients, args.clipping_norm)\n",
    "    sum_of_clipped_grads_from_pb = accumulate_physical_batch(clipped_grads_from_pb, mask)\n",
    "    accumulated_clipped_grads = add_trees(accumulated_clipped_grads, sum_of_clipped_grads_from_pb)\n",
    "\n",
    "    return (\n",
    "        state,\n",
    "        accumulated_clipped_grads,\n",
    "        logical_batch_X,\n",
    "        logical_batch_y,\n",
    "        masks,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Full training loop\n",
    "\n",
    "The below cell executes the main training loop. It consists of the following parts at every step:\n",
    "\n",
    "- Poission sampling of the logical batch size (`poisson_sample_logical_batch_size`): This gives us the logical batch size using Poisson subsampling.\n",
    "- Rounding up of the logical batch size so that there are full physical batches (`setup_physical_batches`): This rounds up the logical batch size so that it is divisible in full physical batches\n",
    "- Padding of the logical batches (`get_padded_logical_batch`): Here we load the actual images and labels.\n",
    "- Computation of the per sample gradients (`jax.lax.fori_loop` using the previously defined `process_physical_batch`): This efficiently computes the per-example gradients of the logical batch.\n",
    "- Addition of noise (`add_Gaussian_noise`): Add the required noise to the accumulated gradients of the logical batch. \n",
    "- Update of the model (`update_model`): Apply the gradient update to the model weights.\n",
    "\n",
    "At the end of a step the following things are executed:\n",
    "- Computation of the throughput: Compute the number of processed examples divided by the time spent.\n",
    "- Evaluate the model (`model_evaluation`): Compute the test accuracy.\n",
    "- Compute the spent privacy budget (`compute_epsilon`): Compute the spent privacy budget using a privacy accountant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 0: 88.8964614868164\n",
      "accuracy at iteration 0: 0.453000009059906\n",
      "{'accountant': 'pld', 'epsilon': 5.95716589775049, 'delta': 9.999999999657339e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 1: 270.6031188964844\n",
      "accuracy at iteration 1: 0.5394999980926514\n",
      "{'accountant': 'pld', 'epsilon': 6.508521466962656, 'delta': 9.999999999519879e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 2: 299.2416076660156\n",
      "accuracy at iteration 2: 0.6230000257492065\n",
      "{'accountant': 'pld', 'epsilon': 6.837246686024637, 'delta': 9.999999999487661e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 3: 259.6731262207031\n",
      "accuracy at iteration 3: 0.6610000133514404\n",
      "{'accountant': 'pld', 'epsilon': 7.080491327747894, 'delta': 9.99999999946578e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 4: 632.8670043945312\n",
      "accuracy at iteration 4: 0.5525000095367432\n",
      "{'accountant': 'pld', 'epsilon': 7.279153079912602, 'delta': 9.999999999469025e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 5: 302.0616455078125\n",
      "accuracy at iteration 5: 0.7254999876022339\n",
      "{'accountant': 'pld', 'epsilon': 7.450765727204071, 'delta': 9.999999999433798e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 6: 310.1956787109375\n",
      "accuracy at iteration 6: 0.6690000295639038\n",
      "{'accountant': 'pld', 'epsilon': 7.604355765923366, 'delta': 9.999999999305473e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 7: 307.54840087890625\n",
      "accuracy at iteration 7: 0.7005000114440918\n",
      "{'accountant': 'pld', 'epsilon': 7.745119949169528, 'delta': 9.999999999315998e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 8: 627.9368286132812\n",
      "accuracy at iteration 8: 0.7565000057220459\n",
      "{'accountant': 'pld', 'epsilon': 7.876283998164701, 'delta': 9.999999999327902e-06}\n",
      "##### Starting gradient accumulation #####\n",
      "throughput at iteration 9: 329.7478332519531\n",
      "accuracy at iteration 9: 0.7170000076293945\n",
      "{'accountant': 'pld', 'epsilon': 7.9999609661919795, 'delta': 9.999999999467209e-06}\n"
     ]
    }
   ],
   "source": [
    "from dpsgdjax.dp_accounting_utils import compute_epsilon\n",
    "from dpsgdjax.jax_mask_efficient import (\n",
    "    get_padded_logical_batch,\n",
    "    model_evaluation,\n",
    "    add_Gaussian_noise,\n",
    "    poisson_sample_logical_batch_size,\n",
    "    setup_physical_batches,\n",
    "    update_model,\n",
    ")\n",
    "\n",
    "times = []\n",
    "logical_batch_sizes = []\n",
    "\n",
    "for t in range(args.num_steps):\n",
    "    sampling_rng = jax.random.key(t + 1)\n",
    "    batch_rng, binomial_rng, noise_rng = jax.random.split(sampling_rng, 3)\n",
    "\n",
    "    #######\n",
    "    # poisson subsample\n",
    "    actual_batch_size = poisson_sample_logical_batch_size(\n",
    "        binomial_rng=binomial_rng, dataset_size=dataset_size, q=subsampling_ratio\n",
    "    )\n",
    "\n",
    "    # determine padded_logical_bs so that there are full physical batches\n",
    "    # and create appropriate masks to mask out unnessary elements later\n",
    "    masks, n_physical_batches = setup_physical_batches(\n",
    "        actual_logical_batch_size=actual_batch_size,\n",
    "        physical_bs=args.physical_bs,\n",
    "    )\n",
    "\n",
    "    # get random padded logical batches that are slighly larger actual batch size\n",
    "    padded_logical_batch_X, padded_logical_batch_y = get_padded_logical_batch(\n",
    "        batch_rng=batch_rng,\n",
    "        padded_logical_batch_size=len(masks),\n",
    "        train_X=train_images,\n",
    "        train_y=train_labels,\n",
    "    )\n",
    "\n",
    "    padded_logical_batch_X = padded_logical_batch_X.reshape(-1, 1, 3, ORIG_IMAGE_DIMENSION, ORIG_IMAGE_DIMENSION)\n",
    "\n",
    "    # cast to GPU\n",
    "    if USE_GPU:\n",
    "        padded_logical_batch_X = jax.device_put(padded_logical_batch_X, jax.devices(\"gpu\")[0])\n",
    "        padded_logical_batch_y = jax.device_put(padded_logical_batch_y, jax.devices(\"gpu\")[0])\n",
    "        masks = jax.device_put(masks, jax.devices(\"gpu\")[0])\n",
    "\n",
    "    print(\"##### Starting gradient accumulation #####\", flush=True)\n",
    "    ### gradient accumulation\n",
    "    params = state.params\n",
    "\n",
    "    accumulated_clipped_grads0 = jax.tree.map(lambda x: 0.0 * x, params)\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    # Main loop\n",
    "    _, accumulated_clipped_grads, *_ = jax.lax.fori_loop(\n",
    "        0,\n",
    "        n_physical_batches,\n",
    "        process_physical_batch,\n",
    "        (\n",
    "            state,\n",
    "            accumulated_clipped_grads0,\n",
    "            padded_logical_batch_X,\n",
    "            padded_logical_batch_y,\n",
    "            masks,\n",
    "        ),\n",
    "    )\n",
    "    noisy_grad = add_Gaussian_noise(noise_rng, accumulated_clipped_grads, noise_std, args.clipping_norm)\n",
    "\n",
    "    # update\n",
    "    state = jax.block_until_ready(update_model(state, noisy_grad))\n",
    "\n",
    "    end = time.time()\n",
    "    duration = end - start\n",
    "\n",
    "    times.append(duration)\n",
    "    logical_batch_sizes.append(actual_batch_size)\n",
    "\n",
    "    print(f\"throughput at iteration {t}: {actual_batch_size / duration}\", flush=True)\n",
    "\n",
    "    acc_iter = model_evaluation(\n",
    "        state, test_images, test_labels, batch_size=10, orig_image_dimension=ORIG_IMAGE_DIMENSION, use_gpu=USE_GPU\n",
    "    )\n",
    "    print(f\"accuracy at iteration {t}: {acc_iter}\", flush=True)\n",
    "\n",
    "    # Compute privacy guarantees\n",
    "    epsilon, delta = compute_epsilon(\n",
    "        noise_multiplier=noise_std,\n",
    "        sample_rate=subsampling_ratio,\n",
    "        steps=t + 1,\n",
    "        target_delta=args.target_delta,\n",
    "        accountant=args.accountant,\n",
    "    )\n",
    "    privacy_results = {\"accountant\": args.accountant, \"epsilon\": epsilon, \"delta\": delta}\n",
    "    print(privacy_results, flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Final Model evaluation\n",
    "Here we computate of the throughput (num processed examples/time spent) and final test accuracy (`model_evaluation`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "times \n",
      " [1.023662805557251, 0.384326696395874, 0.31412744522094727, 0.39280152320861816, 0.1595911979675293, 0.3310582637786865, 0.2965869903564453, 0.3153975009918213, 0.16562175750732422, 0.32752299308776855]\n",
      "batch sizes \n",
      "  [Array(91., dtype=float32), Array(104., dtype=float32), Array(94., dtype=float32), Array(102., dtype=float32), Array(101., dtype=float32), Array(100., dtype=float32), Array(92., dtype=float32), Array(97., dtype=float32), Array(104., dtype=float32), Array(108., dtype=float32)]\n",
      "accuracy at end of training 0.717\n",
      "throughput 342.87716612836016\n"
     ]
    }
   ],
   "source": [
    "acc_last = model_evaluation(state, test_images, test_labels, batch_size=10, use_gpu=USE_GPU, orig_image_dimension=ORIG_IMAGE_DIMENSION)\n",
    "\n",
    "print(\"times \\n\", times, flush=True)\n",
    "\n",
    "print(\"batch sizes \\n \", logical_batch_sizes, flush=True)\n",
    "\n",
    "print(\"accuracy at end of training\", acc_last, flush=True)\n",
    "thr = np.mean(np.array(logical_batch_sizes) / np.array(times))\n",
    "print(\"throughput\", thr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
